# Azure-Event-Hubs-Pipeline
This repo shows the connectivity and event processing using databricks DLT and workflows
# Real-Time IoT Data Pipeline Using Azure Event Hubs + Databricks DLT + Power BI

## üöÄ Overview

This project is a production-ready real-time analytics pipeline designed for streaming IoT data. It uses Azure Event Hubs for ingestion, Databricks Delta Live Tables (DLT) for stream processing, Azure Key Vault for secure credential management, and Power BI for interactive dashboards.

> üí° **Goal**: Detect anomalies in real-time sensor data and visualize metrics using a lakehouse architecture.

---

## üß≠ Architecture
```mermaid
graph TD
    A[Simulated IoT Sensor Data] --> B[Azure Event Hubs]
    B --> C[Databricks DLT Streaming]
    C --> D[Delta Lake tables on Unity Catalog build on ADLS Gen2]
    D --> E[Power BI Dashboard]
    C --> F[Databricks Workflows for Alerting, optional]

```

## üß∞ Tech Stack
Azure Event Hubs: Real-time ingestion of telemetry

Databricks DLT: Stream processing, schema enforcement, Delta Lake

Azure Key Vault: Secure management of secrets (Event Hub credentials, tokens)

Azure Data Lake Storage Gen2: Scalable storage for bronze/silver/gold data layers

Power BI: Real-time reporting and dashboards

Databricks Workflows: Job orchestration and monitoring

GitHub Actions: CI/CD for deploying notebooks and jobs

## üìÅ Lakehouse Layers
Bronze Layer: Raw sensor data from Event Hubs

Silver Layer: Cleansed & transformed data

Gold Layer: Aggregated KPIs for dashboards and alerts
